{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shafqatsarwar/Google_colab_langchain_gemini/blob/main/1st_langgraph_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb1rik7lUo0f"
      },
      "source": [
        "# Research Assistant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CybpXI8mUS-p",
        "outputId": "4afca07d-4855-4ef1-f371-4c37cd1530d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.27.2\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx==0.27.2) (1.2.2)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpx\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.0\n",
            "    Uninstalling httpx-0.28.0:\n",
            "      Successfully uninstalled httpx-0.28.0\n",
            "Successfully installed httpx-0.27.2\n"
          ]
        }
      ],
      "source": [
        "%pip install --quiet -U langgraph langchain langchain_openai langchain_community langchain_core tavily-python wikipedia\n",
        "# %pip install -q -U langchain-google-genai\n",
        "%pip install httpx==0.27.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKn59OwAVowy"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHFnshfDYhQn"
      },
      "source": [
        "we will use chain langsmith for tracing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yh3Bpv5NW-Zm"
      },
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    # Check if the variable is set in the OS environment\n",
        "    env_value = os.environ.get(var)\n",
        "    if not env_value:\n",
        "        # If not set, prompt the user for input\n",
        "        env_value = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "    # Set the environment variable for the current process\n",
        "    os.environ[var] = env_value\n",
        "\n",
        "_set_env(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MsaZu5KYWqP"
      },
      "outputs": [],
      "source": [
        "# # from langchain_openai import ChatOpenAI\n",
        "# from langchain-google-genai import ChatGoogleGenerativeAI\n",
        "# llm = Go(model=\"gpt-4o\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGHuSe2pJo2Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Importing userdata from Google Colab and API keys:\n",
        "# from google.colab import userdata\n",
        "# google_api_key = userdata.get('GEMINI_API_KEY')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nP7y2xqEKfoL"
      },
      "outputs": [],
      "source": [
        "# # Import the ChatGoogleGenerativeAI class from the langchain:\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# # Import the AIMessage:\n",
        "# from langchain_core.messages.ai import AIMessage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfbzQExOKsRU"
      },
      "outputs": [],
      "source": [
        "# # LLM:\n",
        "# llm = ChatGoogleGenerativeAI(\n",
        "#     model=\"gemini-1.5-flash\",  # Specify the model to use\n",
        "#     api_key=google_api_key,     # Use the google_api_key variable here\n",
        "#     temperature=0.2,            # Set the randomness of the model's responses (0 = deterministic, 1 = very random)\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_lmAzOSXidt",
        "outputId": "aea81495-0569-43f9-f9fa-d638e19b8981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model='models/gemini-1.5-flash' google_api_key=SecretStr('**********') temperature=0.2 client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7b9f34eedc60> default_metadata=()\n"
          ]
        }
      ],
      "source": [
        "print(llm)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "# Initialize the model\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
      ],
      "metadata": {
        "id": "4g-fQb9UI0IN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visibility into Trustcall updates\n",
        "Trustcall creates and updates JSON schemas.\n",
        "\n",
        "What if we want visibility into the specific changes made by Trustcall?\n",
        "\n",
        "For example, we saw before that Trustcall has some of its own tools to:\n",
        "\n",
        "Self-correct from validation failures\n",
        "Update existing documents\n",
        "Visibility into these tools can be useful for the agent we're going to build.\n",
        "\n",
        "Below, we'll show how to do this!"
      ],
      "metadata": {
        "id": "AiIfxNjbLPEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Memory(BaseModel):\n",
        "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about Arabic.\")\n",
        "\n",
        "class MemoryCollection(BaseModel):\n",
        "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
      ],
      "metadata": {
        "id": "1-UH87d7K8N-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can add a listener to the Trustcall extractor.\n",
        "\n",
        "This will pass runs from the extractor's execution to a class, Spy, that we will define.\n",
        "\n",
        "Our Spy class will extract information about what tool calls were made by Trustcall."
      ],
      "metadata": {
        "id": "BuWyCHR4LfGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trustcall\n",
        "from trustcall import create_extractor\n",
        "from trustcall import create_extractor\n",
        "\n",
        "# Inspect the tool calls made by Trustcall\n",
        "class Spy:\n",
        "    def __init__(self):\n",
        "        self.called_tools = []\n",
        "\n",
        "    def __call__(self, run):\n",
        "        # Collect information about the tool calls made by the extractor.\n",
        "        q = [run]\n",
        "        while q:\n",
        "            r = q.pop()\n",
        "            if r.child_runs:\n",
        "                q.extend(r.child_runs)\n",
        "            if r.run_type == \"chat_model\":\n",
        "                self.called_tools.append(\n",
        "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
        "                )\n",
        "\n",
        "# Initialize the spy\n",
        "spy = Spy()\n",
        "\n",
        "# Initialize the model\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Create the extractor\n",
        "trustcall_extractor = create_extractor(\n",
        "    model,\n",
        "    tools=[Memory],\n",
        "    tool_choice=\"Memory\",\n",
        "    enable_inserts=True,\n",
        ")\n",
        "\n",
        "# Add the spy as a listener\n",
        "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJouufEZLMxY",
        "outputId": "0ecb84f5-7571-4b6e-cfb0-b8e76ba0eee9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trustcall in /usr/local/lib/python3.10/dist-packages (0.0.26)\n",
            "Requirement already satisfied: dydantic<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from trustcall) (0.0.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from trustcall) (1.33)\n",
            "Requirement already satisfied: langgraph>=0.2.25 in /usr/local/lib/python3.10/dist-packages (from trustcall) (0.2.58)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from dydantic<0.0.8,>=0.0.7->trustcall) (2.10.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->trustcall) (3.0.0)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.10/dist-packages (from langgraph>=0.2.25->trustcall) (0.3.24)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from langgraph>=0.2.25->trustcall) (2.0.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph>=0.2.25->trustcall) (0.1.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.25->trustcall) (6.0.2)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.25->trustcall) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.25->trustcall) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.25->trustcall) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.25->trustcall) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph>=0.2.25->trustcall) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.25->trustcall) (0.27.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.25->trustcall) (3.10.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->dydantic<0.0.8,>=0.0.7->trustcall) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->dydantic<0.0.8,>=0.0.7->trustcall) (2.27.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.25->trustcall) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.25->trustcall) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.25->trustcall) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.25->trustcall) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.25->trustcall) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.25->trustcall) (0.14.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.25->trustcall) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.25->trustcall) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.25->trustcall) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.25->trustcall) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.25->trustcall) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXyTSh29ZLv0"
      },
      "source": [
        "Generat Analyst: Human-in-the-loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# Instruction\n",
        "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
        "\n",
        "# Conversation\n",
        "conversation = [HumanMessage(content=\"Hi, I'm Khan.\"),\n",
        "                AIMessage(content=\"Nice to meet you, Khan.\"),\n",
        "                HumanMessage(content=\"This morning I had a nice bike ride in Lahore.\")]\n",
        "\n",
        "# Invoke the extractor\n",
        "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
      ],
      "metadata": {
        "id": "NlQAGgYpM0Y7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Messages contain the tool calls\n",
        "for m in result[\"messages\"]:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxKiYcFXNA4K",
        "outputId": "b8be8612-8aff-43a7-ad1f-54ba4845e04e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Memory (call_AkkYZB0mMlkPt9K1wAoXmqbV)\n",
            " Call ID: call_AkkYZB0mMlkPt9K1wAoXmqbV\n",
            "  Args:\n",
            "    content: Khan had a nice bike ride in Lahore this morning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Responses contain the memories that adhere to the schema\n",
        "for m in result[\"responses\"]:\n",
        "    print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVbio1XjNGOH",
        "outputId": "7d82d7f5-17d1-4cf8-d59b-25f9b3cba5c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Khan had a nice bike ride in Lahore this morning.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata contains the tool call\n",
        "for m in result[\"response_metadata\"]:\n",
        "    print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1c1AVrPNJ43",
        "outputId": "023dd480-1d58-44d6-b2b0-6408675277ff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'call_AkkYZB0mMlkPt9K1wAoXmqbV'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the conversation\n",
        "updated_conversation = [AIMessage(content=\"That's great, did you do after?\"),\n",
        "                        HumanMessage(content=\"I went to Gulberg.\"),\n",
        "                        AIMessage(content=\"What else is on your mind?\"),\n",
        "                        HumanMessage(content=\"I was thinking about Multan, and going back this winter!\"),]\n",
        "\n",
        "# Update the instruction\n",
        "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
        "\n",
        "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
        "tool_name = \"Memory\"\n",
        "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
        "existing_memories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDiLUqBQNOuB",
        "outputId": "066de851-0540-4e12-851c-ffbc82e6ed51"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('0',\n",
              "  'Memory',\n",
              "  {'content': 'Khan had a nice bike ride in Lahore this morning.'})]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the extractor with our updated conversation and existing memories\n",
        "result = trustcall_extractor_see_all_tool_calls.invoke({\"messages\": updated_conversation,\n",
        "                                                        \"existing\": existing_memories})"
      ],
      "metadata": {
        "id": "k5Y_pnYlNgQo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata contains the tool call\n",
        "for m in result[\"response_metadata\"]:\n",
        "    print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-axCmtgvNmCC",
        "outputId": "38c9f2bb-fa78-4f0f-b4c7-0e4736d6a8dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'call_OE103dUdH9BLC7tYOJLZsMB9', 'json_doc_id': '0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Messages contain the tool calls\n",
        "for m in result[\"messages\"]:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEnBf89YNrWy",
        "outputId": "a695e158-6528-4e26-85ac-228e511cdd4d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Memory (call_OE103dUdH9BLC7tYOJLZsMB9)\n",
            " Call ID: call_OE103dUdH9BLC7tYOJLZsMB9\n",
            "  Args:\n",
            "    content: Khan had a nice bike ride in Lahore this morning. Then, he went to Gulberg. He was also thinking about Multan and going back this winter!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsed responses\n",
        "for m in result[\"responses\"]:\n",
        "    print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q8rzf4eNwTl",
        "outputId": "ad700968-021c-4558-d561-3386d6f6259f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Khan had a nice bike ride in Lahore this morning. Then, he went to Gulberg. He was also thinking about Multan and going back this winter!'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the tool calls made by Trustcall\n",
        "spy.called_tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWDl9ZWxN3WQ",
        "outputId": "0e19bcef-fb76-4027-c875-56383648a49e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'name': 'PatchDoc',\n",
              "   'args': {'json_doc_id': '0',\n",
              "    'planned_edits': \"1. Replace the existing content with the updated memory that includes the user's activities and thoughts. The new content should reflect the bike ride in Lahore, the visit to Gulberg, and thoughts about going to Multan this winter.\",\n",
              "    'patches': [{'op': 'replace',\n",
              "      'path': '/content',\n",
              "      'value': 'Khan had a nice bike ride in Lahore this morning. Then, he went to Gulberg. He was also thinking about Multan and going back this winter!'}]},\n",
              "   'id': 'call_OE103dUdH9BLC7tYOJLZsMB9',\n",
              "   'type': 'tool_call'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tool_info(tool_calls, schema_name=\"Memory\"):\n",
        "    \"\"\"Extract information from tool calls for both patches and new memories.\n",
        "\n",
        "    Args:\n",
        "        tool_calls: List of tool calls from the model\n",
        "        schema_name: Name of the schema tool (e.g., \"Memory\", \"WishList\", \"Profile\")\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize list of changes\n",
        "    changes = []\n",
        "\n",
        "    for call_group in tool_calls:\n",
        "        for call in call_group:\n",
        "            if call['name'] == 'PatchDoc':\n",
        "                changes.append({\n",
        "                    'type': 'update',\n",
        "                    'doc_id': call['args']['json_doc_id'],\n",
        "                    'planned_edits': call['args']['planned_edits'],\n",
        "                    'value': call['args']['patches'][0]['value']\n",
        "                })\n",
        "            elif call['name'] == schema_name:\n",
        "                changes.append({\n",
        "                    'type': 'new',\n",
        "                    'value': call['args']\n",
        "                })\n",
        "\n",
        "    # Format results as a single string\n",
        "    result_parts = []\n",
        "    for change in changes:\n",
        "        if change['type'] == 'update':\n",
        "            result_parts.append(\n",
        "                f\"Document {change['doc_id']} updated:\\n\"\n",
        "                f\"Plan: {change['planned_edits']}\\n\"\n",
        "                f\"Added content: {change['value']}\"\n",
        "            )\n",
        "        else:\n",
        "            result_parts.append(\n",
        "                f\"New {schema_name} created:\\n\"\n",
        "                f\"Content: {change['value']}\"\n",
        "            )\n",
        "\n",
        "    return \"\\n\\n\".join(result_parts)\n",
        "\n",
        "# Inspect spy.called_tools to see exactly what happened during the extraction\n",
        "schema_name = \"Memory\"\n",
        "changes = extract_tool_info(spy.called_tools, schema_name)\n",
        "print(changes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kGKQF_XN8Mo",
        "outputId": "71893642-1ad7-4aee-8f05-da7900a294f5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 0 updated:\n",
            "Plan: 1. Replace the existing content with the updated memory that includes the user's activities and thoughts. The new content should reflect the bike ride in Lahore, the visit to Gulberg, and thoughts about going to Multan this winter.\n",
            "Added content: Khan had a nice bike ride in Lahore this morning. Then, he went to Gulberg. He was also thinking about Multan and going back this winter!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating an agent\n",
        "\n",
        "There are many different architectures to choose from.\n",
        "\n",
        "Here, we'll implement something simple, a React agent.\n",
        "\n",
        "This agent will be a helpful companion for creating and managing a WishList list.\n",
        "\n",
        "This agent can make a decision to update three types of long-term memory:\n",
        "\n",
        "(a) Create or update a user `profile` with general user information\n",
        "\n",
        "(b) Add or update items in a WishList list `collection`\n",
        "\n",
        "(c) Update its own `instructions` on how to update items to the WishList list"
      ],
      "metadata": {
        "id": "lG1yKaPKOSMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Literal\n",
        "\n",
        "# Update memory tool\n",
        "class UpdateMemory(TypedDict):\n",
        "    \"\"\" Decision on what memory type to update \"\"\"\n",
        "    update_type: Literal['user', 'wishlist', 'instructions']"
      ],
      "metadata": {
        "id": "EA0dSVo7Olb6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_set_env(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "YAvhN870O5PI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph definition\n",
        "We add a simple router, route_message, that makes a binary decision to save memories.\n",
        "\n",
        "The memory collection updating is handled by Trustcall in the write_memory node, as before!"
      ],
      "metadata": {
        "id": "9yGhLDHuPD2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from datetime import datetime\n",
        "from trustcall import create_extractor\n",
        "from typing import Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_core.messages import merge_message_runs, HumanMessage, SystemMessage\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, MessagesState, END, START\n",
        "from langgraph.store.base import BaseStore\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize the model\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# User profile schema\n",
        "class Profile(BaseModel):\n",
        "    \"\"\"This is the profile of the user you are chatting with\"\"\"\n",
        "    name: Optional[str] = Field(description=\"The user's name\", default=None)\n",
        "    location: Optional[str] = Field(description=\"The user's location\", default=None)\n",
        "    job: Optional[str] = Field(description=\"The user's job\", default=None)\n",
        "    connections: list[str] = Field(\n",
        "        description=\"Personal connection of the user, such as family members, friends, or coworkers\",\n",
        "        default_factory=list\n",
        "    )\n",
        "    interests: list[str] = Field(\n",
        "        description=\"Interests that the user has\",\n",
        "        default_factory=list\n",
        "    )\n",
        "\n",
        "# WishList schema\n",
        "class WishList(BaseModel):\n",
        "    task: str = Field(description=\"The task to be completed.\")\n",
        "    time_to_complete: Optional[int] = Field(description=\"Estimated time to complete the task (minutes).\")\n",
        "    deadline: Optional[datetime] = Field(\n",
        "        description=\"When the task needs to be completed by (if applicable)\",\n",
        "        default=None\n",
        "    )\n",
        "    solutions: list[str] = Field(\n",
        "        description=\"List of specific, actionable solutions (e.g., specific ideas, service providers, or concrete options relevant to completing the task)\",\n",
        "        min_items=1,\n",
        "        default_factory=list\n",
        "    )\n",
        "    status: Literal[\"not started\", \"in progress\", \"done\", \"archived\"] = Field(\n",
        "        description=\"Current status of the task\",\n",
        "        default=\"not started\"\n",
        "    )\n",
        "\n",
        "# Create the Trustcall extractor for updating the user profile\n",
        "profile_extractor = create_extractor(\n",
        "    model,\n",
        "    tools=[Profile],\n",
        "    tool_choice=\"Profile\",\n",
        ")\n",
        "\n",
        "# Chatbot instruction for choosing what to update and what tools to call\n",
        "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot.\n",
        "\n",
        "You are designed to be a companion to a user, helping them keep track of their WishList list.\n",
        "\n",
        "You have a long term memory which keeps track of three things:\n",
        "1. The user's profile (general information about them)\n",
        "2. The user's WishList list\n",
        "3. General instructions for updating the WishList list\n",
        "\n",
        "Here is the current User Profile (may be empty if no information has been collected yet):\n",
        "<user_profile>\n",
        "{user_profile}\n",
        "</user_profile>\n",
        "\n",
        "Here is the current WishList List (may be empty if no tasks have been added yet):\n",
        "<wishlist>\n",
        "{wishlist}\n",
        "</wishlist>\n",
        "\n",
        "Here are the current user-specified preferences for updating the WishList list (may be empty if no preferences have been specified yet):\n",
        "<instructions>\n",
        "{instructions}\n",
        "</instructions>\n",
        "\n",
        "Here are your instructions for reasoning about the user's messages:\n",
        "\n",
        "1. Reason carefully about the user's messages as presented below.\n",
        "\n",
        "2. Decide whether any of the your long-term memory should be updated:\n",
        "- If personal information was provided about the user, update the user's profile by calling UpdateMemory tool with type `user`\n",
        "- If tasks are mentioned, update the WishList list by calling UpdateMemory tool with type `wishlist`\n",
        "- If the user has specified preferences for how to update the WishList list, update the instructions by calling UpdateMemory tool with type `instructions`\n",
        "\n",
        "3. Tell the user that you have updated your memory, if appropriate:\n",
        "- Do not tell the user you have updated the user's profile\n",
        "- Tell the user them when you update the wishlist list\n",
        "- Do not tell the user that you have updated instructions\n",
        "\n",
        "4. Err on the side of updating the wishlist list. No need to ask for explicit permission.\n",
        "\n",
        "5. Respond naturally to user user after a tool call was made to save memories, or if no tool call was made.\"\"\"\n",
        "\n",
        "# Trustcall instruction\n",
        "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction.\n",
        "\n",
        "Use the provided tools to retain any necessary memories about the user.\n",
        "\n",
        "Use parallel tool calling to handle updates and insertions simultaneously.\n",
        "\n",
        "System Time: {time}\"\"\"\n",
        "\n",
        "# Instructions for updating the WishList list\n",
        "CREATE_INSTRUCTIONS = \"\"\"Reflect on the following interaction.\n",
        "\n",
        "Based on this interaction, update your instructions for how to update WishList list items.\n",
        "\n",
        "Use any feedback from the user to update how they like to have items added, etc.\n",
        "\n",
        "Your current instructions are:\n",
        "\n",
        "<current_instructions>\n",
        "{current_instructions}\n",
        "</current_instructions>\"\"\"\n",
        "\n",
        "# Node definitions\n",
        "def chat_mAIstro(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
        "\n",
        "    # Get the user ID from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # Retrieve profile memory from the store\n",
        "    namespace = (\"profile\", user_id)\n",
        "    memories = store.search(namespace)\n",
        "    if memories:\n",
        "        user_profile = memories[0].value\n",
        "    else:\n",
        "        user_profile = None\n",
        "\n",
        "    # Retrieve task memory from the store\n",
        "    namespace = (\"wishlist\", user_id)\n",
        "    memories = store.search(namespace)\n",
        "    wishlist = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
        "\n",
        "    # Retrieve custom instructions\n",
        "    namespace = (\"instructions\", user_id)\n",
        "    memories = store.search(namespace)\n",
        "    if memories:\n",
        "        instructions = memories[0].value\n",
        "    else:\n",
        "        instructions = \"\"\n",
        "\n",
        "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, wishlist=wishlist, instructions=instructions)\n",
        "\n",
        "    # Respond using memory as well as the chat history\n",
        "    response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
        "\n",
        "    # Get the user ID from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # Define the namespace for the memories\n",
        "    namespace = (\"profile\", user_id)\n",
        "\n",
        "    # Retrieve the most recent memories for context\n",
        "    existing_items = store.search(namespace)\n",
        "\n",
        "    # Format the existing memories for the Trustcall extractor\n",
        "    tool_name = \"Profile\"\n",
        "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
        "                          for existing_item in existing_items]\n",
        "                          if existing_items\n",
        "                          else None\n",
        "                        )\n",
        "\n",
        "    # Merge the chat history and the instruction\n",
        "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
        "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
        "\n",
        "    # Invoke the extractor\n",
        "    result = profile_extractor.invoke({\"messages\": updated_messages,\n",
        "                                         \"existing\": existing_memories})\n",
        "\n",
        "    # Save the memories from Trustcall to the store\n",
        "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
        "        store.put(namespace,\n",
        "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
        "                  r.model_dump(mode=\"json\"),\n",
        "            )\n",
        "    tool_calls = state['messages'][-1].tool_calls\n",
        "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
        "\n",
        "def update_wishlists(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
        "\n",
        "    # Get the user ID from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # Define the namespace for the memories\n",
        "    namespace = (\"wishlist\", user_id)\n",
        "\n",
        "    # Retrieve the most recent memories for context\n",
        "    existing_items = store.search(namespace)\n",
        "\n",
        "    # Format the existing memories for the Trustcall extractor\n",
        "    tool_name = \"WishList\"\n",
        "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
        "                          for existing_item in existing_items]\n",
        "                          if existing_items\n",
        "                          else None\n",
        "                        )\n",
        "\n",
        "    # Merge the chat history and the instruction\n",
        "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
        "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
        "\n",
        "    # Initialize the spy for visibility into the tool calls made by Trustcall\n",
        "    spy = Spy()\n",
        "\n",
        "    # Create the Trustcall extractor for updating the WishList list\n",
        "    wishlist_extractor = create_extractor(\n",
        "    model,\n",
        "    tools=[WishList],\n",
        "    tool_choice=tool_name,\n",
        "    enable_inserts=True\n",
        "    ).with_listeners(on_end=spy)\n",
        "\n",
        "    # Invoke the extractor\n",
        "    result = wishlist_extractor.invoke({\"messages\": updated_messages,\n",
        "                                    \"existing\": existing_memories})\n",
        "\n",
        "    # Save the memories from Trustcall to the store\n",
        "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
        "        store.put(namespace,\n",
        "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
        "                  r.model_dump(mode=\"json\"),\n",
        "            )\n",
        "\n",
        "    # Respond to the tool call made in chat_mAIstro, confirming the update\n",
        "    tool_calls = state['messages'][-1].tool_calls\n",
        "\n",
        "    # Extract the changes made by Trustcall and add the the ToolMessage returned to chat_mAIstro\n",
        "    wishlist_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
        "    return {\"messages\": [{\"role\": \"tool\", \"content\": wishlist_update_msg, \"tool_call_id\":tool_calls[0]['id']}]}\n",
        "\n",
        "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
        "\n",
        "    # Get the user ID from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    namespace = (\"instructions\", user_id)\n",
        "\n",
        "    existing_memory = store.get(namespace, \"user_instructions\")\n",
        "\n",
        "    # Format the memory in the system prompt\n",
        "    system_msg = CREATE_INSTRUCTIONS.format(current_instructions=existing_memory.value if existing_memory else None)\n",
        "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'][:-1] + [HumanMessage(content=\"Please update the instructions based on the conversation\")])\n",
        "\n",
        "    # Overwrite the existing memory in the store\n",
        "    key = \"user_instructions\"\n",
        "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
        "    tool_calls = state['messages'][-1].tool_calls\n",
        "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated instructions\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
        "\n",
        "# Conditional edge\n",
        "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_wishlists\", \"update_instructions\", \"update_profile\"]:\n",
        "\n",
        "    \"\"\"Reflect on the memories and chat history to decide whether to update the memory collection.\"\"\"\n",
        "    message = state['messages'][-1]\n",
        "    if len(message.tool_calls) ==0:\n",
        "        return END\n",
        "    else:\n",
        "        tool_call = message.tool_calls[0]\n",
        "        if tool_call['args']['update_type'] == \"user\":\n",
        "            return \"update_profile\"\n",
        "        elif tool_call['args']['update_type'] == \"wishlist\":\n",
        "            return \"update_wishlists\"\n",
        "        elif tool_call['args']['update_type'] == \"instructions\":\n",
        "            return \"update_instructions\"\n",
        "        else:\n",
        "            raise ValueError\n",
        "\n"
      ],
      "metadata": {
        "id": "sKj2MSMfPI1i"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define graph logic, nodes and edge"
      ],
      "metadata": {
        "id": "XUup-DXXPNqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the graph + all nodes\n",
        "builder = StateGraph(MessagesState)\n",
        "\n",
        "# Define the flow of the memory extraction process\n",
        "builder.add_node(chat_mAIstro)\n",
        "builder.add_node(update_wishlists)\n",
        "builder.add_node(update_profile)\n",
        "builder.add_node(update_instructions)\n",
        "builder.add_edge(START, \"chat_mAIstro\")\n",
        "builder.add_conditional_edges(\"chat_mAIstro\", route_message)\n",
        "builder.add_edge(\"update_wishlists\", \"chat_mAIstro\")\n",
        "builder.add_edge(\"update_profile\", \"chat_mAIstro\")\n",
        "builder.add_edge(\"update_instructions\", \"chat_mAIstro\")\n",
        "\n",
        "# Store for long-term (across-thread) memory\n",
        "across_thread_memory = InMemoryStore()\n",
        "\n",
        "# Checkpointer for short-term (within-thread) memory\n",
        "within_thread_memory = MemorySaver()\n",
        "\n",
        "# We compile the graph with the checkpointer and store\n",
        "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
        "\n",
        "# View\n",
        "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "Z__TB7EFPT18",
        "outputId": "d63760ba-007d-4e23-92bf-47063e2519fa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test your graph\n",
        "provide some basic detais\n",
        "\n",
        "thread ID for short-term (within-thread) memory\n",
        "\n",
        "user ID for long-term (across-thread) memory"
      ],
      "metadata": {
        "id": "CVagXpmURsFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We supply a thread ID for short-term (within-thread) memory\n",
        "# We supply a user ID for long-term (across-thread) memory\n",
        "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"Khan\"}}\n",
        "\n",
        "# User input to create a profile memory\n",
        "input_messages = [HumanMessage(content=\"My name is Khan. I live in Lahore with my family. I have 3 family memberat my house.\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZzojqQFNznO",
        "outputId": "2d0e1a69-eca7-4aac-e357-d49a67e7cbe0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "My name is Khan. I live in Lahore with my family. I have 3 family memberat my house.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UpdateMemory (call_PqHb1iiSy6M7RTg0OmLrXPXT)\n",
            " Call ID: call_PqHb1iiSy6M7RTg0OmLrXPXT\n",
            "  Args:\n",
            "    update_type: user\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "updated profile\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Got it, Khan! If there's anything you'd like to add to your WishList or if you have any specific preferences, feel free to let me know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User input for a ToDo\n",
        "input_messages = [HumanMessage(content=\"My sister asked me to book swim lessons for her.\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZqvRnR8SarV",
        "outputId": "b88183a2-9173-429e-c7ba-363890c63920"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "My sister asked me to book swim lessons for her.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UpdateMemory (call_amMzrEjFZ1TsfhRCH4z7GXyb)\n",
            " Call ID: call_amMzrEjFZ1TsfhRCH4z7GXyb\n",
            "  Args:\n",
            "    update_type: wishlist\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "New WishList created:\n",
            "Content: {'task': 'Book swim lessons for sister', 'time_to_complete': 60, 'solutions': ['Check local swimming pools for lesson availability', 'Look for private swim instructors online', 'Consider group classes for better rates'], 'status': 'not started'}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I've added \"Book swim lessons for sister\" to your WishList. If you need any help with this task or want to update it, just let me know!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User input to update instructions for creating Wish Lists\n",
        "input_messages = [HumanMessage(content=\"When creating or updating WishList items, include specific local businesses / vendors.\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1InMdNYSqs3",
        "outputId": "7eebf92b-bd28-407b-97c5-7f7f1e644ca8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "When creating or updating WishList items, include specific local businesses / vendors.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UpdateMemory (call_PmvG4gCi6osGe6Tw1xjhrvNT)\n",
            " Call ID: call_PmvG4gCi6osGe6Tw1xjhrvNT\n",
            "  Args:\n",
            "    update_type: instructions\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "updated instructions\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Got it! I'll make sure to include specific local businesses or vendors when creating or updating your WishList items. If there's anything else you'd like to adjust, just let me know!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for updated instructions\n",
        "user_id = \"Khan\"\n",
        "\n",
        "# Search\n",
        "for memory in across_thread_memory.search((\"instructions\", user_id)):\n",
        "    print(memory.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Btnq1_5S5RW",
        "outputId": "379829d5-8a61-4a23-a2de-2867702efeb7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'memory': 'Based on your feedback, here are the updated instructions for managing your WishList items:\\n\\n1. **Task Description**: Clearly state the task or item to be added to the WishList.\\n   \\n2. **Local Recommendations**: Include specific local businesses or vendors relevant to the task. For example, if booking swim lessons, suggest local swimming pools or instructors in the area.\\n\\n3. **Time to Complete**: Estimate the time required to complete the task, if applicable.\\n\\n4. **Solutions/Options**: Provide a list of potential solutions or options to accomplish the task, including local options.\\n\\n5. **Status**: Track the status of the task (e.g., not started, in progress, completed).\\n\\nIf you have any more preferences or need further customization, feel free to let me know!'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User input for a WishList\n",
        "input_messages = [HumanMessage(content=\"I need to fix the jammed electric Yale lock on the car door.\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-MJKZf2TBpU",
        "outputId": "99d74492-bb52-4d8e-a389-161aa3601823"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I need to fix the jammed electric Yale lock on the car door.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UpdateMemory (call_3BPyvgi7nkVN5D5WH3L324Pp)\n",
            " Call ID: call_3BPyvgi7nkVN5D5WH3L324Pp\n",
            "  Args:\n",
            "    update_type: wishlist\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "New WishList created:\n",
            "Content: {'task': 'Fix jammed electric Yale lock on car door', 'time_to_complete': 90, 'solutions': ['Contact local locksmiths specializing in car locks', 'Check for Yale service centers nearby', 'Look for DIY repair guides online'], 'status': 'not started'}\n",
            "\n",
            "Document 1296a173-60c9-4efb-ae78-52bf4c3f17b6 updated:\n",
            "Plan: Add specific local businesses or vendors to the solutions for booking swim lessons.\n",
            "Added content: ['Check local swimming pools like Lahore Gymkhana or Punjab Club for lesson availability', 'Look for private swim instructors online through platforms like OLX or local Facebook groups', 'Consider group classes at community centers such as Model Town Club for better rates']\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I've added \"Fix jammed electric Yale lock on car door\" to your WishList. If you need any assistance or further updates, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Namespace for the memory to save\n",
        "user_id = \"Khan\"\n",
        "\n",
        "# Search\n",
        "for memory in across_thread_memory.search((\"wishlist\", user_id)):\n",
        "    print(memory.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGcGs54gS06G",
        "outputId": "9b281738-6a7d-4fde-ed40-79f2bda6883e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'task': 'Book swim lessons for sister', 'time_to_complete': 60, 'deadline': None, 'solutions': ['Check local swimming pools like Lahore Gymkhana or Punjab Club for lesson availability', 'Look for private swim instructors online through platforms like OLX or local Facebook groups', 'Consider group classes at community centers such as Model Town Club for better rates'], 'status': 'not started'}\n",
            "{'task': 'Fix jammed electric Yale lock on car door', 'time_to_complete': 90, 'deadline': None, 'solutions': ['Contact local locksmiths specializing in car locks', 'Check for Yale service centers nearby', 'Look for DIY repair guides online'], 'status': 'not started'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User input to update an existing Wish List\n",
        "input_messages = [HumanMessage(content=\"For the swim lessons, I need to get that done by end of March.\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUBGvpMnS1T6",
        "outputId": "a1537459-365b-491c-ea6d-4b3b3c160d31"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "For the swim lessons, I need to get that done by end of March.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UpdateMemory (call_RfTWYFDynlkcD6Dtu12Xtyhx)\n",
            " Call ID: call_RfTWYFDynlkcD6Dtu12Xtyhx\n",
            "  Args:\n",
            "    update_type: wishlist\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "Document 1296a173-60c9-4efb-ae78-52bf4c3f17b6 updated:\n",
            "Plan: Add a deadline to the task for booking swim lessons to ensure it is completed by the end of March.\n",
            "Added content: 2025-03-31T23:59:59\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I've updated the swim lessons task with a deadline for the end of March. If there's anything else you'd like to adjust, just let me know!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that Trustcall performs patching of the existing memory:"
      ],
      "metadata": {
        "id": "qSplF2ztTjNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User input for a Wish List\n",
        "input_messages = [HumanMessage(content=\"Need to call back City Toyota to schedule car service.\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UCN2EXWTtot",
        "outputId": "ecd4188c-90a5-4af7-f683-37cdead8a33e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Need to call back City Toyota to schedule car service.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UpdateMemory (call_HuBmumtOEgVCk3zCLMPg2VTw)\n",
            " Call ID: call_HuBmumtOEgVCk3zCLMPg2VTw\n",
            "  Args:\n",
            "    update_type: wishlist\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "New WishList created:\n",
            "Content: {'task': 'Call back City Toyota to schedule car service', 'time_to_complete': 15, 'solutions': ['Find the contact number for City Toyota', 'Check available dates for service', 'Prepare any questions or concerns about the car service'], 'status': 'not started'}\n",
            "\n",
            "Document fd85015d-4832-40c0-a30e-9ed18d1e6142 updated:\n",
            "Plan: Add specific local businesses or vendors to the solutions for fixing the jammed electric Yale lock.\n",
            "Added content: Contact local locksmiths like Lahore Lock Masters or City Lock Services specializing in car locks\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I've added \"Call back City Toyota to schedule car service\" to your WishList. If you need any help with this task or want to update it, just let me know!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Namespace for the memory to save\n",
        "user_id = \"Khan\"\n",
        "\n",
        "# Search\n",
        "for memory in across_thread_memory.search((\"wishlist\", user_id)):\n",
        "    print(memory.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRwGPmRkT4HI",
        "outputId": "de1ee768-e324-49ef-967b-9378d0a5d413"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'task': 'Book swim lessons for sister', 'time_to_complete': 60, 'deadline': '2025-03-31T23:59:59', 'solutions': ['Check local swimming pools like Lahore Gymkhana or Punjab Club for lesson availability', 'Look for private swim instructors online through platforms like OLX or local Facebook groups', 'Consider group classes at community centers such as Model Town Club for better rates'], 'status': 'not started'}\n",
            "{'task': 'Fix jammed electric Yale lock on car door', 'time_to_complete': 90, 'deadline': None, 'solutions': ['Contact local locksmiths like Lahore Lock Masters or City Lock Services specializing in car locks', 'Check for Yale service centers nearby, such as the one in Gulberg', 'Look for DIY repair guides online, such as YouTube tutorials or auto repair forums'], 'status': 'not started'}\n",
            "{'task': 'Call back City Toyota to schedule car service', 'time_to_complete': 15, 'deadline': None, 'solutions': ['Find the contact number for City Toyota', 'Check available dates for service', 'Prepare any questions or concerns about the car service'], 'status': 'not started'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can create a new thread.\n",
        "\n",
        "This creates a new session.\n",
        "\n",
        "Profile, WishList, and Instructions saved to long-term memory are accessed."
      ],
      "metadata": {
        "id": "J72PAr9eUDng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We supply a thread ID for short-term (within-thread) memory\n",
        "# We supply a user ID for long-term (across-thread) memory\n",
        "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"Khan\"}}\n",
        "\n",
        "# Chat with the chatbot\n",
        "input_messages = [HumanMessage(content=\"I have 30 minutes, what tasks can I get done?\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRB1g7htUKFY",
        "outputId": "d0344944-b466-4283-dfac-c67e2f8bd0e1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I have 30 minutes, what tasks can I get done?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Based on your available time, you can complete the following task from your WishList:\n",
            "\n",
            "- **Call back City Toyota to schedule car service**: This task is estimated to take 15 minutes.\n",
            "\n",
            "Would you like to proceed with this task, or do you need any assistance with it?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat with the chatbot\n",
        "input_messages = [HumanMessage(content=\"Yes, give me some options to call for swim lessons.\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3bSzaGwUGFx",
        "outputId": "eb4abf94-b8bd-4acc-afab-6602f6022817"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Yes, give me some options to call for swim lessons.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here are some options for booking swim lessons in Lahore:\n",
            "\n",
            "1. **Local Swimming Pools**:\n",
            "   - Lahore Gymkhana: Check their availability for swim lessons.\n",
            "   - Punjab Club: Inquire about their swim lesson schedules.\n",
            "\n",
            "2. **Private Swim Instructors**:\n",
            "   - Look for instructors on platforms like OLX or local Facebook groups where private lessons might be advertised.\n",
            "\n",
            "3. **Community Centers**:\n",
            "   - Model Town Club: They might offer group classes, which could be more cost-effective.\n",
            "\n",
            "If you need more information or help with contacting any of these options, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IZDGh_1-T0AP"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFQkkb4XI6fLPh+fe9u9sA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}